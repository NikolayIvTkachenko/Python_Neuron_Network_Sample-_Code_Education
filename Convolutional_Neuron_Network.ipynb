{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a7d8cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__ is 2.1.0\n",
      "tf.keras.__version__ is: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "print(\"tf.__version__ is\", tf.__version__)\n",
    "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the ConvNet\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "        \n",
    "        #CONV => RELU => POOL\n",
    "        model.add(Conv2D(20, kernel_size=(5, 5), padding=\"same\", input_shape=input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        #CONV => RELU => POOL\n",
    "        model.add(Conv2D(50, kernel_size=(5, 5), padding='same'))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        #layer Flatten => RELU\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        #softmax - classificator\n",
    "        #model.add(Dense(classes))\n",
    "        #model.add(Activation(\"softmax\"))\n",
    "        model.add(Dense(classes, activation = 'softmax'))\n",
    "        return model\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network and education\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT=0.2\n",
    "IMG_ROWS, IMG_COLS = 28, 28\n",
    "NB_CLASSES = 10\n",
    "INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)\n",
    "\n",
    "#education and test data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#K.set_image_dim_ordering(\"th\")\n",
    "#K.image_data_format(\"th\")\n",
    "#K.image_data_format()\n",
    "#K.set_image_data_format('channels_first')\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, IMG_ROWS, IMG_COLS)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, IMG_ROWS, IMG_COLS)\n",
    "    input_shape = (1, IMG_ROWS, IMG_COLS)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], IMG_ROWS, IMG_COLS, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], IMG_ROWS, IMG_COLS, 1)\n",
    "    input_shape = (IMG_ROWS, IMG_COLS, 1)\n",
    "    \n",
    "#Normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#forma 60k x [1 x 28 x 28] send to input covolution network\n",
    "#X_train = X_test[:, np.newaxis, :, :]\n",
    "#X_test = X_test[:, np.newaxis, :, :]\n",
    "print(X_train.shape[0], 'test samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#translate vectors classes in binary matrix classes\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "#Initialization optimizator and model\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE,\n",
    "                   validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])\n",
    "\n",
    "#count all datta in history\n",
    "print(history.history.keys())\n",
    "\n",
    "#build graphics accurancy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#build graphics loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d372739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e32c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-30-20760a63356f>:16: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.1896 - accuracy: 0.9420 - val_loss: 0.0648 - val_accuracy: 0.9801\n",
      "Epoch 2/20\n",
      "26112/48000 [===============>..............] - ETA: 25s - loss: 0.0519 - accuracy: 0.9842"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.test.is_gpu_available()\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "from tensorflow import keras\n",
    "#import segmentation_models as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1671)  # for reproducibility\n",
    "\n",
    "#define the convnet \n",
    "class LeNet:\n",
    "\t@staticmethod\n",
    "\tdef build(input_shape, classes):\n",
    "\t\tmodel = Sequential()\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(Conv2D(20, kernel_size=5, padding=\"same\",\n",
    "\t\t\tinput_shape=input_shape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(Conv2D(50, kernel_size=5, padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1'))\n",
    "\t\t# Flatten => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(500))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    " \n",
    "\t\t# a softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\treturn model\n",
    "\n",
    "# network and training\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "IMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\n",
    "NB_CLASSES = 10  # number of outputs = number of digits\n",
    "INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#K.set_image_dim_ordering(\"th\")\n",
    "#K.image_data_format()\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "# consider them as float and normalize\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 \n",
    "X_test /= 255  \n",
    "\n",
    "# we need a 60K x [1 x 28 x 28] shape as input to the CONVNET\n",
    "X_train = X_train[:, np.newaxis, :, :]\n",
    "X_test = X_test[:, np.newaxis, :, :]\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# initialize the optimizer and model\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH, \n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ea075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
